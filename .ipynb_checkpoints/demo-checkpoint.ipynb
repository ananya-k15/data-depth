{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14229331-ac21-4540-b461-9f9d0bf658cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import eigh\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from depth.multivariate import *\n",
    "from numpy.random import RandomState\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial import ConvexHull, Delaunay\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd2c05a8-11e6-4a8a-b663-46531fd5c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE Model Definition\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, hidden_dim, z_dim=10):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(x_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, z_dim*2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, x_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, logvar = torch.chunk(h, 2, dim=1)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decoder(z), z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98de4867-5856-4f9f-942f-bdac2b0cfbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "# Train VAE\n",
    "def train_model(model, dataloader, learning_rate, num_epochs):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        for batch in dataloader:\n",
    "            x, _ = batch\n",
    "            x = x.view(x.size(0), -1)\n",
    "            optimizer.zero_grad()\n",
    "            recon_x, z, mu, logvar = model(x)\n",
    "            loss = loss_function(recon_x, x, mu, logvar)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch + 1}, Loss: {train_loss / len(dataloader.dataset)}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e48f847c-7791-4249-b61c-b35afc776fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion-MNIST dataset\n",
    "def load_data(normal_class=0):\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])\n",
    "    fashion_mnist_train = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=False)\n",
    "    fashion_mnist_test = datasets.FashionMNIST(root='./data', train=False, transform=transform, download=False)\n",
    "    \n",
    "    # Filter out only the normal class\n",
    "    train_indices = [i for i, (_, label) in enumerate(fashion_mnist_train) if label == normal_class]\n",
    "    normal_train = Subset(fashion_mnist_train, train_indices)\n",
    "    \n",
    "    return normal_train, fashion_mnist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "462474a5-fd39-4be3-8749-ba5e889bd258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Mahalanobis depth\n",
    "def compute_mahalanobis_depth(latent_space):\n",
    "    mean = np.mean(latent_space, axis=0)\n",
    "    cov = np.cov(latent_space, rowvar=False)\n",
    "    inv_cov = np.linalg.inv(cov)\n",
    "    depth = np.array([distance.mahalanobis(x, mean, inv_cov) for x in latent_space])\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8132fc76-f7ba-4988-a857-d37eed1d13fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 518.3347415364583\n",
      "Epoch 2, Loss: 438.5036634114583\n"
     ]
    }
   ],
   "source": [
    "# # Main function\n",
    "# def main():\n",
    "normal_train, fashion_mnist_test = load_data(normal_class=0)  # Class 0: T-shirt/top\n",
    "\n",
    "dataloader = DataLoader(normal_train, batch_size=128, shuffle=True)\n",
    "\n",
    "# Define VAE model\n",
    "x_dim = 28 * 28\n",
    "hidden_dim = 256\n",
    "latent_dim = 50\n",
    "model = VAE(x_dim=x_dim, hidden_dim=hidden_dim, z_dim=latent_dim)\n",
    "\n",
    "# Train VAE\n",
    "trained_model = train_model(model, dataloader, learning_rate=1e-4, num_epochs=2)\n",
    "\n",
    "# Obtain latent representations\n",
    "latent_space = []\n",
    "labels = []\n",
    "depths = []\n",
    "bno = 1\n",
    "trained_model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in fashion_mnist_test:\n",
    "        # get latent shape\n",
    "        x, y = batch\n",
    "        x = x.view(-1, x.size(0))\n",
    "        _, z, _, _ = trained_model(x)\n",
    "        latent_space.append(z.cpu().numpy())\n",
    "        # y-labels\n",
    "        labels.append(torch.tensor(y).cpu().numpy())\n",
    "        # computing data_depth\n",
    "        print(\"Computing data depth for batch\", bno)\n",
    "        batch_depths = halfspace(np.array(labels), np.array(latent_space))\n",
    "        depths.append(batch_depths)\n",
    "        print(\"Added depths for batch\", bno) \n",
    "        bno += 1\n",
    "        \n",
    "latent_space = np.concatenate(latent_space, axis=0)\n",
    "labels = np.concatenate([labels], axis=0)\n",
    "depths = np.concatenate(batch_depths, axis=0)\n",
    "\n",
    "print(latent_space.shape)\n",
    "print(labels.shape)\n",
    "print(depths.shape)\n",
    "\n",
    "    # Compute Mahalanobis depth\n",
    "    # data_depth = compute_mahalanobis_depth(latent_space)\n",
    "    # data_depth = halfspace(latent_space, latent_space)\n",
    "    \n",
    "    # # Set a threshold for anomalies (e.g., top 5% deepest points)\n",
    "    # threshold = np.percentile(data_depth, 95)\n",
    "    # anomalies = data_depth > threshold\n",
    "\n",
    "    # # Visualize latent space with anomalies\n",
    "    # plt.scatter(latent_space[:, 0], latent_space[:, 1], c='blue', label='Normal')\n",
    "    # plt.scatter(latent_space[anomalies, 0], latent_space[anomalies, 1], c='red', label='Anomalies')\n",
    "    # plt.title('Latent Space')\n",
    "    # plt.xlabel('Latent Dimension 1')\n",
    "    # plt.ylabel('Latent Dimension 2')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    # # Visualize original and reconstructed anomalies\n",
    "    # anomaly_indices = np.where(anomalies)[0]\n",
    "    # for i in anomaly_indices[:10]:  # Show up to 10 anomalies\n",
    "    #     original = fashion_mnist_test[i][0].view(28, 28).numpy()\n",
    "    #     with torch.no_grad():\n",
    "    #         reconstructed, _, _, _ = trained_model(fashion_mnist_test[i][0].view(-1))\n",
    "    #     reconstructed = reconstructed.view(28, 28).numpy()\n",
    "        \n",
    "    #     fig, axes = plt.subplots(1, 2)\n",
    "    #     axes[0].imshow(original, cmap='gray')\n",
    "    #     axes[0].set_title('Original')\n",
    "    #     axes[1].imshow(reconstructed, cmap='gray')\n",
    "    #     axes[1].set_title('Reconstructed')\n",
    "    #     plt.show()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe7482d-51cc-445a-ace6-c3d12e555c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
