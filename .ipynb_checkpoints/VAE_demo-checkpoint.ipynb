{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /Users/DELL/opt/anaconda3/lib/python3.9/site-packages (0.17.2)\n",
      "Requirement already satisfied: torch==2.2.2 in /Users/DELL/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (2.2.2)\n",
      "Requirement already satisfied: numpy in /Users/DELL/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (2.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/DELL/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: filelock in /Users/DELL/opt/anaconda3/lib/python3.9/site-packages (from torch==2.2.2->torchvision) (3.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/DELL/opt/anaconda3/lib/python3.9/site-packages (from torch==2.2.2->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/DELL/opt/anaconda3/lib/python3.9/site-packages (from torch==2.2.2->torchvision) (2.6.3)\n",
      "Requirement already satisfied: sympy in /Users/DELL/opt/anaconda3/lib/python3.9/site-packages (from torch==2.2.2->torchvision) (1.9)\n",
      "Requirement already satisfied: fsspec in /Users/DELL/opt/anaconda3/lib/python3.9/site-packages (from torch==2.2.2->torchvision) (2021.8.1)\n",
      "Requirement already satisfied: jinja2 in /Users/DELL/opt/anaconda3/lib/python3.9/site-packages (from torch==2.2.2->torchvision) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/DELL/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch==2.2.2->torchvision) (1.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/DELL/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch==2.2.2->torchvision) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Q9S8QaLPKnBL"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import torch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_qOmgQR_Qvv8"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(\n",
    "          self,\n",
    "          x_dim,\n",
    "          hidden_dim,\n",
    "          z_dim=10\n",
    "        ):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Define autoencoding layers\n",
    "        self.enc_layer1 = nn.Linear(x_dim, hidden_dim)\n",
    "        self.enc_layer2_mu = nn.Linear(hidden_dim, z_dim)\n",
    "        self.enc_layer2_logvar = nn.Linear(hidden_dim, z_dim)\n",
    "\n",
    "        # Define autoencoding layers\n",
    "        self.dec_layer1 = nn.Linear(z_dim, hidden_dim)\n",
    "        self.dec_layer2 = nn.Linear(hidden_dim, x_dim)\n",
    "\n",
    "    def encoder(self, x):\n",
    "        x = F.relu(self.enc_layer1(x))\n",
    "        mu = F.relu(self.enc_layer2_mu(x))\n",
    "        logvar = F.relu(self.enc_layer2_logvar(x))\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(logvar/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + std * eps\n",
    "        return z\n",
    "\n",
    "    def decoder(self, z):\n",
    "        # Define decoder network\n",
    "        output = F.relu(self.dec_layer1(z))\n",
    "        output = F.relu(self.dec_layer2(output))\n",
    "        return output\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        output = self.decoder(z)\n",
    "        return output, z, mu, logvar\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(output, x, mu, logvar):\n",
    "    recon_loss = F.mse_loss(output, x, reduction='sum') / x.size(0)\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + 0.002  * kl_loss\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    dataloader,\n",
    "    learning_rate=1e-4,\n",
    "    # batch_size=128,\n",
    "    num_epochs=15,\n",
    "    # hidden_dim=256,\n",
    "    # latent_dim=50\n",
    "  ):\n",
    "  # # Define the VAE model\n",
    "  # model = VAE_simple(x_dim=X.shape[1], hidden_dim=hidden_dim, z_dim=latent_dim)\n",
    "\n",
    "  # Define the optimizer\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  # # Convert X to a PyTorch tensor\n",
    "  # X = torch.tensor(X).float()\n",
    "\n",
    "  # # Create DataLoader object to generate minibatches\n",
    "  # dataset = TensorDataset(X)\n",
    "  # dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  # Train the model\n",
    "  for epoch in range(num_epochs):\n",
    "      epoch_loss = 0\n",
    "      for batch in dataloader:\n",
    "          # Zero the gradients\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          # Get batch\n",
    "          x = batch[0]\n",
    "\n",
    "          # Forward pass\n",
    "          output, z, mu, logvar = model(x)\n",
    "\n",
    "          # Calculate loss\n",
    "          loss = loss_function(output, x, mu, logvar)\n",
    "\n",
    "          # Backward pass\n",
    "          loss.backward()\n",
    "\n",
    "          # Update parameters\n",
    "          optimizer.step()\n",
    "\n",
    "          # Add batch loss to epoch loss\n",
    "          epoch_loss += loss.item()\n",
    "\n",
    "      # Print epoch loss\n",
    "      print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(dataloader.dataset)}\")\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2FzHCp3wTl_1"
   },
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])\n",
    "    mnist_test = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "    test_loader = DataLoader(mnist_test, batch_size=128, shuffle=False)\n",
    "    return test_loader\n",
    "\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch in test_loader:\n",
    "            x, _ = batch\n",
    "            x = x.view(x.size(0), -1)  # Flatten the images\n",
    "\n",
    "            # Forward pass\n",
    "            output, z, mu, logvar = model(x)\n",
    "            loss = loss_function(output, x, mu, logvar)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6BaiTqlMTtFd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_reconstruction(model, test_loader, num_images=10):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch in test_loader:\n",
    "            x, _ = batch\n",
    "            x = x.view(x.size(0), -1)  # Flatten the images\n",
    "\n",
    "            # Forward pass\n",
    "            output, _, _, _ = model(x)\n",
    "            break  # We only need a single batch for visualization\n",
    "\n",
    "    # Plot the original and reconstructed images\n",
    "    x = x.view(-1, 28, 28)\n",
    "    output = output.view(-1, 28, 28)\n",
    "    fig, axes = plt.subplots(2, num_images, figsize=(15, 3))\n",
    "    for i in range(num_images):\n",
    "        axes[0, i].imshow(x[i].cpu().numpy(), cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "        axes[1, i].imshow(output[i].cpu().numpy(), cmap='gray')\n",
    "        axes[1, i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOTv2IZEMZOj"
   },
   "outputs": [],
   "source": [
    "def main() :\n",
    "  # Load MNIST dataset\n",
    "  transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])\n",
    "  mnist_train = datasets.MNIST(root='./data', train=True, transform=transform, download=False)\n",
    "  dataloader = DataLoader(mnist_train, batch_size=128, shuffle=True)\n",
    "\n",
    "  # Define the VAE model\n",
    "  x_dim = 28 * 28  # MNIST images are 28x28\n",
    "  hidden_dim = 256\n",
    "  latent_dim = 50\n",
    "  model = VAE(x_dim=x_dim, hidden_dim=hidden_dim, z_dim=latent_dim)\n",
    "\n",
    "  trained_model = train_model(model, dataloader, learning_rate=1e-4, num_epochs=15)\n",
    "\n",
    "  # Load test data\n",
    "  test_loader = load_test_data()\n",
    "\n",
    "  # Test the VAE model\n",
    "  test_model(trained_model, test_loader)\n",
    "\n",
    "  # Visualize reconstructions\n",
    "  visualize_reconstruction(trained_model, test_loader, num_images=10)\n",
    "\n",
    "  # train VAE to learn latent dimension\n",
    "  # train it to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "es2ReMnFRA1x",
    "outputId": "262e81de-fa42-498f-fd67-c2ab87c7ab12"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2uqDznTBTtxv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
